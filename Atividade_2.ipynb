{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_UB4Al1_bo7S"
   },
   "source": [
    "Considere o artigo:\n",
    "```python\n",
    "Bloice, M.D., Holzinger, A. (2016). A Tutorial on Machine Learning and Data Science Tools with Python.\n",
    "```\n",
    "In: Holzinger, A. (eds) Machine Learning for Health Informatics.<br> Lecture Notes in Computer Science(), vol 9605. Springer, Cham. <br>https://doi.org/10.1007/978-3-319-50478-0_22\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QFMnFkBTdFWP"
   },
   "source": [
    "Utilizando as bibliotecas `PyMuPDF` e `Regex`, faça a extração do texto e apresente todas as **URLs** presentes no artigo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "imQqn0MR1yMy"
   },
   "source": [
    "Acesso ao Formulário para envio do código:\n",
    "* https://forms.gle/D54GFxjB8s6ZqkPo9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== URLs no PDF ===\n",
      "1. 10.1007/978-3-319-50478-0\n",
      "2. 10.1007/978-3-642-40763-5\n",
      "3. fibonacci.py\n",
      "4. http://augmentor.readthedocs.io\n",
      "5. http://augmentorjl.readthedocs.io\n",
      "6. http://cacm.acm.org/blogs/blog-cacm/176450-\n",
      "7. http://cacm.acm.org/blogs/blog-cacm/176450-python-is-now-the-most-popular-introductory-teaching-language-at-top-u-s-universities\n",
      "8. http://developer.nvidia.com/digits\n",
      "9. http://dx.doi.org/10.1007/978-3-642-40763-5_51\n",
      "10. http://localhost:8888/\n",
      "11. http://mathesaurus.sourceforge.net/matlab-numpy.html\n",
      "12. http://pandas\n",
      "13. http://pandas.pydata.org/pandas-docs/stable/missing\n",
      "14. http://pandas.pydata.org/pandas-docs/stable/missing_data.html\n",
      "15. http://pandas.pydata.org/pandas-docs/stable/visualization.html\n",
      "16. http://pydata.org/pandas-docs/stable/visualization.html\n",
      "17. http://scikit-learn.org/stable/documentation.html\n",
      "18. http://topepo.github.io/caret/index.html\n",
      "19. http://torch.ch/docs/getting-started.html\n",
      "20. http://www.cancer.gov\n",
      "21. http://www.scipy-lectures.org/\n",
      "22. http://www.scipy-lectures.org/_images/numpy_indexing.png\n",
      "23. https://developer.nvidia.com/digits\n",
      "24. https://github.com/mdbloice/MLDS\n",
      "25. https://twitter.com/fchollet/status/\n",
      "26. https://twitter.com/fchollet/status/765212287531495424\n",
      "27. https://visualsonline.cancer.gov/details.cfm\n",
      "28. https://visualsonline.cancer.gov/details.cfm?imageid=10583\n",
      "29. https://www.continuum.io/downloads\n",
      "30. https://www.tensorflow.org/get_started/os_setup.html\n",
      "31. https://www.tensorﬂow.org/get\n"
     ]
    }
   ],
   "source": [
    "import pdfx\n",
    "import re\n",
    "\n",
    "def reconstruct_broken_urls(raw_urls):\n",
    "    \"\"\"\n",
    "    Reconstrói URLs que foram fragmentadas ou incompletas no texto extraído.\n",
    "    \"\"\"\n",
    "    reconstructed_urls = []\n",
    "    for url in raw_urls:\n",
    "        # Limpar espaços extras\n",
    "        url = url.strip()\n",
    "\n",
    "        # Reunir URLs quebradas por espaços\n",
    "        url = re.sub(r'\\s+', '', url)\n",
    "\n",
    "        # Substituir caracteres estranhos ao final das URLs\n",
    "        url = re.sub(r'[.,;:!?]+$', '', url)\n",
    "\n",
    "        # Tentar identificar fragmentos incompletos (como palavras separadas por espaço ou falta de barras)\n",
    "        if re.match(r'https?://', url) or re.match(r'www\\.', url):\n",
    "            reconstructed_urls.append(url)\n",
    "        elif re.search(r'\\.html|\\.org|\\.com|\\.io|\\.gov|\\.net|\\.edu', url):  # Reconhecer domínios comuns\n",
    "            if 'http' not in url:\n",
    "                reconstructed_urls.append('http://' + url)\n",
    "            else:\n",
    "                reconstructed_urls.append(url)\n",
    "        else:\n",
    "            # URLs aparentemente incompletas são adicionadas para posterior verificação\n",
    "            reconstructed_urls.append(url)\n",
    "\n",
    "    # Remover duplicatas e ordenar\n",
    "    return sorted(set(reconstructed_urls))\n",
    "\n",
    "def extract_pdf_data(pdf_path):\n",
    "    \"\"\"\n",
    "    Extrai URLs de um PDF e tenta reconstruí-las se estiverem incompletas.\n",
    "    \"\"\"\n",
    "    # Carregar o PDF com pdfx\n",
    "    pdf = pdfx.PDFx(pdf_path)\n",
    "\n",
    "    # Extrair URLs\n",
    "    references = pdf.get_references_as_dict()\n",
    "    raw_urls = references.get('url', [])\n",
    "\n",
    "    # Reconstruir e limpar URLs\n",
    "    fixed_urls = reconstruct_broken_urls(raw_urls)\n",
    "\n",
    "    # Exibir URLs no console\n",
    "    print(\"\\n=== URLs no PDF ===\")\n",
    "    for i, url in enumerate(fixed_urls, start=1):\n",
    "        print(f\"{i}. {url}\")\n",
    "\n",
    "# Caminho do PDF\n",
    "pdf_path = \"artigoAtividade2.pdf\"\n",
    "\n",
    "# Executar extração de dados\n",
    "extract_pdf_data(pdf_path)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
